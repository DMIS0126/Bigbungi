{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0a23c6a",
   "metadata": {
    "papermill": {
     "duration": 0.002428,
     "end_time": "2022-11-27T12:54:29.118087",
     "exception": false,
     "start_time": "2022-11-27T12:54:29.115659",
     "status": "completed"
    },
    "tags": []
   },
   "source": [

   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7e2f08",
   "metadata": {
    "papermill": {
     "duration": 0.001567,
     "end_time": "2022-11-27T12:54:29.121441",
     "exception": false,
     "start_time": "2022-11-27T12:54:29.119874",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Q. [ë§ˆì¼€íŒ…] ìë™ì°¨ ì‹œì¥ ì„¸ë¶„í™”\n",
    "- ìë™ì°¨ íšŒì‚¬ëŠ” ìƒˆë¡œìš´ ì „ëµì„ ìˆ˜ë¦½í•˜ê¸° ìœ„í•´ 4ê°œì˜ ì‹œì¥ìœ¼ë¡œ ì„¸ë¶„í™”í–ˆìŠµë‹ˆë‹¤.\n",
    "- ê¸°ì¡´ ê³ ê° ë¶„ë¥˜ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹ ê·œ ê³ ê°ì´ ì–´ë–¤ ë¶„ë¥˜ì— ì†í• ì§€ ì˜ˆì¸¡í•´ì£¼ì„¸ìš”!\n",
    "\n",
    "\n",
    "- ì˜ˆì¸¡í•  ê°’(y): \"Segmentation\" (1,2,3,4)\n",
    "- í‰ê°€: Macro f1-score\n",
    "- data: train.csv, test.csv\n",
    "- ì œì¶œ í˜•ì‹: \n",
    "~~~\n",
    "ID,Segmentation\n",
    "458989,1\n",
    "458994,2\n",
    "459000,3\n",
    "459003,4\n",
    "~~~\n",
    "\n",
    "### ë‹µì•ˆ ì œì¶œ ì°¸ê³ \n",
    "- ì•„ë˜ ì½”ë“œ ì˜ˆì¸¡ë³€ìˆ˜ì™€ ìˆ˜í—˜ë²ˆí˜¸ë¥¼ ê°œì¸ë³„ë¡œ ë³€ê²½í•˜ì—¬ í™œìš© \n",
    "- pd.DataFrame({'ID': test.ID, 'Segmentation': pred}).to_csv('003000000.csv', index=False)\n",
    "\n",
    "### ë…¸íŠ¸ë¶ êµ¬ë¶„\n",
    "- basic: ìˆ˜ì¹˜í˜• ë°ì´í„°ë§Œ í™œìš© -> í•™ìŠµ ë° testë°ì´í„° ì˜ˆì¸¡\n",
    "- intermediate: ë²”ì£¼í˜• ë°ì´í„°ë„ í™œìš© -> í•™ìŠµ ë° testë°ì´í„° ì˜ˆì¸¡\n",
    "- advanced: í•™ìŠµ ë° êµì°¨ ê²€ì¦(ëª¨ë¸ í‰ê°€) -> í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ -> testë°ì´í„° ì˜ˆì¸¡\n",
    "\n",
    "### í•™ìŠµì„ ìœ„í•œ ì±„ì \n",
    "- ìµœì¢… íŒŒì¼ì„ \"ìˆ˜í—˜ë²ˆí˜¸.csv\"ê°€ ì•„ë‹Œ \"submission.csv\" ì‘ì„± í›„ ì˜¤ë¥¸ìª½ ë©”ë‰´ ì•„ë˜ \"submit\" ë²„íŠ¼ í´ë¦­ -> ë¦¬ë”ë³´ë“œì— ì ìˆ˜ ë° ë“±ìˆ˜ í™•ì¸ ê°€ëŠ¥í•¨\n",
    "- pd.DataFrame({'ID': test.ID, 'Segmentation': pred}).to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188388d5",
   "metadata": {
    "papermill": {
     "duration": 0.001292,
     "end_time": "2022-11-27T12:54:29.124257",
     "exception": false,
     "start_time": "2022-11-27T12:54:29.122965",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ğŸ§‘â€ğŸ’» ë‚´ í’€ì´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21eca7e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T12:54:29.129318Z",
     "iopub.status.busy": "2022-11-27T12:54:29.128832Z",
     "iopub.status.idle": "2022-11-27T12:54:30.365837Z",
     "shell.execute_reply": "2022-11-27T12:54:30.364561Z"
    },
    "papermill": {
     "duration": 1.242911,
     "end_time": "2022-11-27T12:54:30.368691",
     "exception": false,
     "start_time": "2022-11-27T12:54:29.125780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ë°ì´í„° ê¸°ì´ˆ ì •ë³´ í™•ì¸\n",
    "import pandas as pd\n",
    "x_train = pd.read_csv('/kaggle/input/big-data-analytics-certification-kr-2022/train.csv')\n",
    "# y_train = x_train.pop('Segmentation')\n",
    "# x_train\n",
    "# y_train\n",
    "x_test = pd.read_csv('/kaggle/input/big-data-analytics-certification-kr-2022/test.csv')\n",
    "# x_test\n",
    "\n",
    "# print(x_train.info())\n",
    "# ê²°ì¸¡ì¹˜ê°€ ì—†êµ°\n",
    "\n",
    "x_train_ID = x_train.pop('ID')\n",
    "x_test_ID = x_test.pop('ID')\n",
    "\n",
    "# LabelEncodingí•˜ê¸°\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "x_train['Gender'] = encoder.fit_transform(x_train['Gender'])\n",
    "x_train['Ever_Married'] = encoder.fit_transform(x_train['Ever_Married'])\n",
    "x_train['Graduated'] = encoder.fit_transform(x_train['Graduated'])\n",
    "x_train['Profession'] = encoder.fit_transform(x_train['Profession'])\n",
    "x_train['Spending_Score'] = encoder.fit_transform(x_train['Spending_Score'])\n",
    "x_train['Var_1'] = encoder.fit_transform(x_train['Var_1'])\n",
    "\n",
    "x_test['Gender'] = encoder.fit_transform(x_test['Gender'])\n",
    "x_test['Ever_Married'] = encoder.fit_transform(x_test['Ever_Married'])\n",
    "x_test['Graduated'] = encoder.fit_transform(x_test['Graduated'])\n",
    "x_test['Profession'] = encoder.fit_transform(x_test['Profession'])\n",
    "x_test['Spending_Score'] = encoder.fit_transform(x_test['Spending_Score'])\n",
    "x_test['Var_1'] = encoder.fit_transform(x_test['Var_1'])\n",
    "\n",
    "\n",
    "# x_train.info()\n",
    "# x_train.corr()\n",
    "\n",
    "# Ever_Marriedì™€ Spending_Scoreê°€ ìƒê´€ê´€ê³„ê°€ ë†’ìœ¼ë¯€ë¡œ(0.6 ì´ìƒ) Spending_Score ì‚­ì œ\n",
    "# x_train.drop(columns = ['Spending_Score', 'Age'], inplace = True)\n",
    "# x_test.drop(columns = ['Spending_Score', 'Age'], inplace = True)\n",
    "\n",
    "# y_train ë§Œë“¤ê¸°\n",
    "y_train = x_train.pop('Segmentation')\n",
    "# print(y_train)\n",
    "\n",
    "# x_train, x_test ìŠ¤ì¼€ì¼ë§í•˜ê¸°\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler1 = StandardScaler()\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler2 = RobustScaler()\n",
    "\n",
    "# í‘œì¤€í™”\n",
    "x_train = pd.DataFrame(scaler1.fit_transform(x_train), columns = x_train.columns)\n",
    "x_test = pd.DataFrame(scaler1.fit_transform(x_test), columns = x_test.columns)\n",
    "\n",
    "# # ë¡œë²„ìŠ¤íŠ¸ ìŠ¤ì¼€ì¼ë§\n",
    "# x_train = pd.DataFrame(scaler2.fit_transform(x_train), columns = x_train.columns)\n",
    "# x_test = pd.DataFrame(scaler2.fit_transform(x_test), columns = x_test.columns)\n",
    "\n",
    "# ì§€ê¸ˆ ì œëŒ€ë¡œ ì•Œê³  ìˆëŠ” ê²ƒì´ ì˜ì‚¬ê²°ì •ë‚˜ë¬´ë°–ì— ì—†ìœ¼ë¯€ë¡œ ê·¸ê±°ë¼ë„ ì¨ë³´ê¸°\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(max_depth = 5, criterion = 'entropy')\n",
    "\n",
    "# í•™ìŠµ\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "y_test = pd.DataFrame(model.predict(x_test))\n",
    "y_test\n",
    "\n",
    "result = pd.concat([x_test_ID, y_test], axis = 1)\n",
    "result.columns = ['ID', 'Segmentation']\n",
    "result.to_csv('Submission.csv', index = False)\n",
    "\n",
    "# score : 0.32147\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # XGBoost ë¶„ë¥˜ê¸° ì¨ë³´ê¸°\n",
    "# from xgboost import XGBRegressor\n",
    "# model = XGBRegressor(n_estimatios = 100, max_depth = 3)\n",
    "# model.fit(x_train, y_train)\n",
    "\n",
    "# # ì˜ˆì¸¡\n",
    "# y_test = pd.DataFrame(model.predict(x_test))\n",
    "# # y_test\n",
    "\n",
    "# result = pd.concat([x_test_ID, y_test], axis = 1)\n",
    "# result.columns = ['ID', 'Segmentation']\n",
    "# result['Segmentation'] = round(result['Segmentation'], 0).astype(int)\n",
    "\n",
    "# result.to_csv('Submission.csv', index = False)\n",
    "# result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9.510318,
   "end_time": "2022-11-27T12:54:31.093483",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-27T12:54:21.583165",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
